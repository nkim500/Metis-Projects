{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc021511-a7ec-4bcb-9ade-5f73154cd8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import pathlib\n",
    "import shutil\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image as pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10666f3e-daf4-4f2a-835d-500821679aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = pathlib.Path(\"brain_tumor 2/training\")\n",
    "test_dir = pathlib.Path(\"brain_tumor 2/validation\")\n",
    "pred_dir = pathlib.Path(\"brain_tumor 2/test\")\n",
    "\n",
    "batch = 256\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "img_size = (img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d510156e-69fe-4ab8-8ffd-e7ad836051b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7465 images belonging to 2 classes.\n",
      "Found 1047 images belonging to 2 classes.\n",
      "Found 1511 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "imagegenerator = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = imagegenerator.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch,\n",
    "    target_size=img_size,\n",
    "    seed=2021,\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_gen = imagegenerator.flow_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=batch,\n",
    "    target_size=img_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "pred_gen = imagegenerator.flow_from_directory(\n",
    "    pred_dir,\n",
    "    batch_size=batch,\n",
    "    target_size=img_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c57ba27f-a4f5-4fda-8b64-660732ada733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4654e96b-7765-47be-b3f1-5ffcc1cb854e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 112, 112, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 112, 112, 64)      102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 56, 56, 10)        31370     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 31360)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31361     \n",
      "=================================================================\n",
      "Total params: 193,835\n",
      "Trainable params: 193,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_expand = Sequential()\n",
    "\n",
    "model_expand.add(InputLayer(input_shape=(224,224,3)))\n",
    "\n",
    "model_expand.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "model_expand.add(MaxPooling2D())\n",
    "\n",
    "model_expand.add(Conv2D(filters=32, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "model_expand.add(Conv2D(filters=64, kernel_size=3, activation='relu', padding='same'))\n",
    "\n",
    "model_expand.add(Conv2D(filters=64, kernel_size=5, activation='relu', padding='same'))\n",
    "model_expand.add(MaxPooling2D())\n",
    "\n",
    "model_expand.add(Conv2D(filters=10, kernel_size=7, activation='relu', padding='same'))\n",
    "model_expand.add(Flatten())\n",
    "model_expand.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_expand.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_expand.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de243f70-3aa3-4a03-837a-f2555ab19851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 1322s 44s/step - loss: 0.6234 - accuracy: 0.7328 - val_loss: 0.5471 - val_accuracy: 0.7230\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 1243s 41s/step - loss: 0.3905 - accuracy: 0.8269 - val_loss: 0.5122 - val_accuracy: 0.7775\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 1206s 40s/step - loss: 0.2930 - accuracy: 0.8770 - val_loss: 0.4838 - val_accuracy: 0.8099\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 1234s 41s/step - loss: 0.2303 - accuracy: 0.9084 - val_loss: 0.4812 - val_accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 1264s 42s/step - loss: 0.1912 - accuracy: 0.9283 - val_loss: 0.5968 - val_accuracy: 0.8309\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 1285s 43s/step - loss: 0.1463 - accuracy: 0.9504 - val_loss: 0.4077 - val_accuracy: 0.8720\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 1435s 48s/step - loss: 0.1114 - accuracy: 0.9633 - val_loss: 0.3554 - val_accuracy: 0.8883\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 1153s 38s/step - loss: 0.0878 - accuracy: 0.9707 - val_loss: 0.3659 - val_accuracy: 0.9064\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 1137s 38s/step - loss: 0.0721 - accuracy: 0.9771 - val_loss: 0.3650 - val_accuracy: 0.8997\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 1135s 38s/step - loss: 0.0646 - accuracy: 0.9763 - val_loss: 0.3799 - val_accuracy: 0.9121\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 1146s 38s/step - loss: 0.0456 - accuracy: 0.9854 - val_loss: 0.3683 - val_accuracy: 0.9179\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 1164s 39s/step - loss: 0.0384 - accuracy: 0.9865 - val_loss: 0.4648 - val_accuracy: 0.9140\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 1148s 38s/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.4493 - val_accuracy: 0.9226\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 1129s 38s/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.5136 - val_accuracy: 0.9217\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 1135s 38s/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.6021 - val_accuracy: 0.9226\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 1156s 40s/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.5994 - val_accuracy: 0.9245\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 1218s 41s/step - loss: 0.0084 - accuracy: 0.9983 - val_loss: 0.5944 - val_accuracy: 0.9236\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "result_expand = model_expand.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=test_gen,\n",
    "#     steps_per_epoch=100,\n",
    "    epochs=100,\n",
    "    callbacks=[EarlyStopping(patience=10, verbose=1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cb4ec2-18e5-4926-a992-61e533fb5681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 22:55:01.841028: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 68s 11s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model_expand.predict(pred_gen, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68973890-0c79-4f9d-a2e0-32740113fee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9735274652547982\n",
      "0.9701789264413518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "\n",
    "print(accuracy_score(pred_gen.classes, predictions.round(0)))\n",
    "print(recall_score(pred_gen.classes, predictions.round(0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8159b1de-e8b3-4144-af09-2e620f2c285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_expand.save(\"custom_cnn_expanded_data.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f7c796-aafd-4010-a88e-fecec805fc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 22:54:58.038125: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-02 22:54:58.038498: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model_expand = tf.keras.models.load_model(\"custom_cnn_expanded_data.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c781e-f74c-4398-82cd-f249a2449bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
