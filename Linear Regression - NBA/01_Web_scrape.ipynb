{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9126c947-fd19-413e-9029-19717c266ecb",
   "metadata": {},
   "source": [
    "#### Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc3156a-cf59-40de-997c-6a0650a3c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from bs4 import Comment\n",
    "import requests\n",
    "import time, os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e7b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import boxcox \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bdc094-3758-4d0f-a97e-f110f503068a",
   "metadata": {},
   "source": [
    "Set up the web scraper for www.basketball-reference.com to collect basketball stat and data on Google Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4497448-2286-4b3c-ac50-2fd9fec12f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = '/Applications/chromedriver'\n",
    "os.environ['webdriver.chrome.driver'] = chromedriver\n",
    "\n",
    "urltest = \"https://www.basketball-reference.com/players/c/curryst01.html\"\n",
    "restest = requests.get(urltest)\n",
    "urlmain = \"https://www.basketball-reference.com/contracts/players.html\"\n",
    "res = requests.get(urlmain)\n",
    "# players = bs(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4efefcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robot = \"https://www.basketball-reference.com/robots.txt\"\n",
    "\n",
    "response = requests.get(robot)\n",
    "requests.get(robot).status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69cf11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "951e3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(res.text, \"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "05f4fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_p = soup.find_all(\"tbody\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a9d8e-46d2-4414-88d2-02e875fcd000",
   "metadata": {},
   "source": [
    "Web scraper below will collect NBA player names and their profile URL links in a dictionary format, which will become the basis for the web scraper to collect all necessary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b6d6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = bs(res.text, \"html5lib\")\n",
    "soup_p = soup.find_all(\"tbody\")[-1]\n",
    "\n",
    "def linkcollect(s):\n",
    "    s_link = s.find(\"td\", class_='left').find('a').get('href')\n",
    "    s_name = s.find('td',class_='left').find_all('a')[-1].text\n",
    "    s_team = s.find_all(\"td\", class_='left')[1].find('a').text\n",
    "    s_salary = s.find('td',class_='right').text\n",
    "    headers = ['link','pname','team','salary']\n",
    "    player_dict = dict(zip(headers, [s_link,s_name,s_team,s_salary]))\n",
    "    return player_dict\n",
    "\n",
    "player_dict=[]                       \n",
    "       \n",
    "# There are 2 line breaks after every 21 rows of tables on page. Could have been done with slicing but to be certain:\n",
    "\n",
    "for i in range(0,590):\n",
    "    s = soup_p.find_all(\"tr\")[i]\n",
    "    if i in [20,21,42,43,64,65,86,87,108,109,130,131,152,153,174,175,196,197,218,219\\\n",
    "            ,240,241,262,263,284,285,306,307,328,329,350,351,372,373,394,395,416,417\\\n",
    "            ,438,439,460,461,482,483,504,505,526,527,548,549,570,571]:\n",
    "        pass\n",
    "    else:\n",
    "        player_dict.append(linkcollect(s))\n",
    "    print(i)\n",
    "\n",
    "# player_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "2ffd0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurls = pd.DataFrame(player_dict)\n",
    "playerurls.set_index('pname', inplace=True)\n",
    "playerurls.head()\n",
    "playerurls.to_csv(\"playerurls.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a76f8289",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerurls = pd.read_csv('playerurls.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e38e1-fe0b-43c4-a64b-8534c0d71225",
   "metadata": {},
   "source": [
    "Using the dictionary of NBA players and the corresponding URL, web scraper/helper function will collect per season stats of each player in the script below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "2250b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playerseason(x):\n",
    "    website = 'https://www.basketball-reference.com'\n",
    "    url = website + x\n",
    "    res = requests.get(url)\n",
    "    page = res.text\n",
    "    soup = bs(page,'html5lib')\n",
    "    bio = soup.select_one('div[itemtype=\"https://schema.org/Person\"]')\n",
    "\n",
    "    headers = ['player_name','height','weight','season','age','team','pos','gameplayed',\\\n",
    "              'gamestarted','minpergame','fgmade','fgattempt','fgpct','threemade',\\\n",
    "              'threeattempt','threepct','twomade','twoattempt','twopct','efgpct',\\\n",
    "              'ftmade','ftattempt','ftpct','offreb','defreb','allreb','assist',\\\n",
    "              'steals','blocks','turnov','pfouls','points']\n",
    "    \n",
    "    if soup.select_one('table[id=\"per_game\"]') != None:\n",
    "        per_game = soup.select_one('table[id=\"per_game\"]')\n",
    "        cbody = soup.select_one('div[id=\"all_all_salaries\"]')\n",
    "        comment = cbody.find(text=lambda text:isinstance(text, Comment))\n",
    "        commentsoup = bs(comment, 'html5lib')\n",
    "        saltable = commentsoup.find_all('tr')[:]\n",
    "\n",
    "    \n",
    "    # Name\n",
    "    player_name = bio.find('h1').find('span').text\n",
    "    #Height\n",
    "    height = bio.select_one('span[itemprop=\"height\"]').text\n",
    "    #Weight\n",
    "    weight = bio.select_one('span[itemprop=\"weight\"]').text\n",
    "    \n",
    "\n",
    "    dict_list = []\n",
    "\n",
    "    if soup.select_one('table[id=\"per_game\"]') != None:\n",
    "        if per_game.find_all('tr') != None:\n",
    "            for i in range(1,len(per_game.find_all('tr'))-1):\n",
    "\n",
    "                pgtr = per_game.find_all('tr')\n",
    "                try:\n",
    "                    season = pgtr[i].get('id')[-4:]\n",
    "                except: \n",
    "                    season = ''\n",
    "\n",
    "                row = pgtr[i]\n",
    "\n",
    "                try:\n",
    "                    age = row.select_one('td[data-stat=\"age\"]').text\n",
    "                except:\n",
    "                    age = ''\n",
    "\n",
    "                try:\n",
    "                    team = row.select_one('td[data-stat=\"team_id\"]').text\n",
    "                except:\n",
    "                    team = ''\n",
    "\n",
    "                try:\n",
    "                    pos = row.select_one('td[data-stat=\"pos\"]').text\n",
    "                except:\n",
    "                    pos = ''\n",
    "\n",
    "                try:\n",
    "                    gameplayed = row.select_one('td[data-stat=\"g\"]').text\n",
    "                except:\n",
    "                    gameplayed = ''\n",
    "\n",
    "                try:\n",
    "                    gamestarted = row.select_one('td[data-stat=\"gs\"]').text\n",
    "                except:\n",
    "                    gamestarted = ''\n",
    "\n",
    "                try:\n",
    "                    minpergame = row.select_one('td[data-stat=\"mp_per_g\"]').text\n",
    "                except:\n",
    "                    minpergame = ''\n",
    "\n",
    "                try:\n",
    "                    fgmade = row.select_one('td[data-stat=\"fg_per_g\"]').text\n",
    "                except:\n",
    "                    fgmade = ''\n",
    "\n",
    "                try:\n",
    "                    fgattempt = row.select_one('td[data-stat=\"fga_per_g\"]').text\n",
    "                except:\n",
    "                    fgattempt = ''\n",
    "\n",
    "                try:\n",
    "                    fgpct = row.select_one('td[data-stat=\"fg_pct\"]').text\n",
    "                except:\n",
    "                    fgpct = ''\n",
    "\n",
    "                try:\n",
    "                    threemade = row.select_one('td[data-stat=\"fg3_per_g\"]').text\n",
    "                except:\n",
    "                    threemade = ''\n",
    "\n",
    "                try:\n",
    "                    threeattempt = row.select_one('td[data-stat=\"fg3a_per_g\"]').text\n",
    "                except:\n",
    "                    threeattempt = ''\n",
    "\n",
    "                try:\n",
    "                    threepct = row.select_one('td[data-stat=\"fg3_pct\"]').text\n",
    "                except:\n",
    "                    threepct = ''\n",
    "\n",
    "                try:\n",
    "                    twomade = row.select_one('td[data-stat=\"fg2_per_g\"]').text\n",
    "                except:\n",
    "                    twomade = ''\n",
    "\n",
    "                try:\n",
    "                    twoattempt = row.select_one('td[data-stat=\"fg2a_per_g\"]').text\n",
    "                except:\n",
    "                    twoattempt = ''\n",
    "\n",
    "                try:\n",
    "                    twopct = row.select_one('td[data-stat=\"fg2_pct\"]').text\n",
    "                except:\n",
    "                    twopct = ''\n",
    "\n",
    "                try:\n",
    "                    efgpct = row.select_one('td[data-stat=\"efg_pct\"]').text\n",
    "                except:\n",
    "                    efgpct = ''\n",
    "\n",
    "                try:\n",
    "                    ftmade = row.select_one('td[data-stat=\"ft_per_g\"]').text\n",
    "                except: \n",
    "                    ftmade = ''\n",
    "\n",
    "                try:\n",
    "                    ftattempt = row.select_one('td[data-stat=\"fta_per_g\"]').text\n",
    "                except:\n",
    "                    ftattempt = ''\n",
    "\n",
    "                try:\n",
    "                    ftpct = row.select_one('td[data-stat=\"ft_pct\"]').text\n",
    "                except:\n",
    "                    ftpct = ''\n",
    "\n",
    "                try:\n",
    "                    offreb = row.select_one('td[data-stat=\"orb_per_g\"]').text\n",
    "                except:\n",
    "                    offreb = ''\n",
    "\n",
    "                try:\n",
    "                    defreb = row.select_one('td[data-stat=\"drb_per_g\"]').text\n",
    "                except:\n",
    "                    defreb = ''\n",
    "\n",
    "                try:\n",
    "                    allreb = row.select_one('td[data-stat=\"trb_per_g\"]').text\n",
    "                except:\n",
    "                    allreb = ''\n",
    "\n",
    "                try:\n",
    "                    assist = row.select_one('td[data-stat=\"ast_per_g\"]').text\n",
    "                except:\n",
    "                    assist = ''\n",
    "\n",
    "                try:\n",
    "                    steals = row.select_one('td[data-stat=\"stl_per_g\"]').text\n",
    "                except:\n",
    "                    steals = ''\n",
    "\n",
    "                try:\n",
    "                    blocks = row.select_one('td[data-stat=\"blk_per_g\"]').text\n",
    "                except:\n",
    "                    blocks = ''\n",
    "\n",
    "                try: \n",
    "                    turnov = row.select_one('td[data-stat=\"tov_per_g\"]').text\n",
    "                except:\n",
    "                    turnov = ''\n",
    "\n",
    "                try:\n",
    "                    pfouls = row.select_one('td[data-stat=\"pf_per_g\"]').text\n",
    "                except:\n",
    "                    pfouls = ''\n",
    "\n",
    "                try: \n",
    "                    points = row.select_one('td[data-stat=\"pts_per_g\"]').text\n",
    "                except:\n",
    "                    points = ''\n",
    "\n",
    "                newdict = dict(zip(headers, [player_name,height,weight,\\\n",
    "                                             season,age,team,pos,gameplayed,\\\n",
    "                      gamestarted,minpergame,fgmade,fgattempt,fgpct,threemade,\\\n",
    "                      threeattempt,threepct,twomade,twoattempt,twopct,efgpct,\\\n",
    "                      ftmade,ftattempt,ftpct,offreb,defreb,allreb,assist,\\\n",
    "                      steals,blocks,turnov,pfouls,points]))\n",
    "                dict_list.append(newdict)\n",
    "            \n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7309f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def playersalary(x):\n",
    "    website = 'https://www.basketball-reference.com'\n",
    "    url = website + x\n",
    "    res = requests.get(url)\n",
    "    page = res.text\n",
    "    soup = bs(page,'html5lib')\n",
    "    bio = soup.select_one('div[itemtype=\"https://schema.org/Person\"]')\n",
    "    player_name = bio.find('h1').find('span').text\n",
    "\n",
    "    dict_list = []\n",
    "    headers=['player_name','season','team','salary']\n",
    "    if soup.select_one('table[id=\"per_game\"]') != None:\n",
    "        cbody = soup.select_one('div[id=\"all_all_salaries\"]')\n",
    "        comment = cbody.find(text=lambda text:isinstance(text, Comment))\n",
    "        commentsoup = bs(comment, 'html5lib')\n",
    "        saltable = commentsoup.find_all('tr')[:]\n",
    " \n",
    "        for i in range(1,len(saltable)-1):\n",
    "            soup_s = bs(saltable[i].text,'html5lib')\n",
    "            season = int(soup_s.text[:4])+1\n",
    "            try:\n",
    "                team = saltable[i].find('a').text\n",
    "            except:\n",
    "                team = ''\n",
    "            try:\n",
    "                salary = soup_s.find_all('td')[-1].text\n",
    "            except:\n",
    "                salary = soup_s.text[-11:]\n",
    "\n",
    "            newdict_s = dict(zip(headers,[player_name, season, team, salary]))\n",
    "            dict_list.append(newdict_s)\n",
    "\n",
    "        return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76edd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerstats = [] \n",
    "for link in playerurls.link:\n",
    "    playerstats.append(playerseason(link))\n",
    "\n",
    "pstats = []\n",
    "for i in playerstats:\n",
    "    if i != None: \n",
    "        for j in i:\n",
    "            pstats.append(j)\n",
    "            \n",
    "dfp = pd.DataFrame(pstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "823c1c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "psal2 = []\n",
    "for link in playerurls.link:\n",
    "    psal2.append(playersalary(link))\n",
    "\n",
    "psalary = []\n",
    "for i in psal2:\n",
    "    if i != None:\n",
    "        for j in i:\n",
    "            psalary.append(j)\n",
    "            \n",
    "dfs = pd.DataFrame(psalary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d51e79-0845-4256-96b2-b6c51c9402fb",
   "metadata": {},
   "source": [
    "Checkpoint: Save and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8614e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.to_csv(\"stats.csv\")\n",
    "dfs.to_csv(\"salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "247829c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.read_csv(\"stats.csv\")\n",
    "dfs = pd.read_csv(\"salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "da52fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp.drop(dfp.iloc[:,0:1], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "d2b2f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.drop(dfs.iloc[:,0:1],axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
